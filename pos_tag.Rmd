---
title: 'Part of Speech Tagging Assignment'
author: "Yueze Xu"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
#do not change this
knitr::opts_chunk$set(echo = TRUE)
options(reticulate.repl.quiet = TRUE)
```

## Libraries / R Setup

- In this section, include the libraries you need for the *R* questions.  

```{r warning=FALSE}
##r chunk
#devtools::install_github("bradleyboehmke/harrypotter")
#setwd("C:/Users/hera-/Desktop/HU/ANLY520")
library(harrypotter)
library(reticulate)
py_config()
library(tagger)
library(dplyr)
library(rJava)
library(RDRPOSTagger)
##pick one of the harrypotter books to analyze with your POS text
##https://github.com/bradleyboehmke/harrypotter check out the options
##load it using data(book title)
data(half_blood_prince)
content = half_blood_prince[1]

py_module_available("spacy")
py_module_available("nltk")
```

- In this section, include import functions to load the packages you will use for Python.
- Also transfer your `book_data` from R into Python.  

```{python}
##python chunk
import spacy
import nltk
import pandas as pd
from nltk.corpus import brown
book_data = r.content
```

## Tagger Package

- Use the `tagger` package to tag your chosen book and print out the first chapter only (i.e., row 1 of the book you chose). 
- Use something like `(book[1])[[1]][1:10]` to print out the first few tags. 
- Use the universal tag set and plot options to see what the most common parts of speech are for your chapter.
- What are the top two most common parts of speech? \
**The top two most common parts are "NOUN" and "VERB"**

```{r warning=FALSE}
##r chunk
sentence = py$book_data
tag_pos = tag_pos(sentence)
print(tag_pos[[1]][1:10])#first few tags
tag_pos(sentence) %>% plot()
tag_pos(sentence) %>% as_universal() %>% plot()

```

## RDR POS Tagger

- Create an English language model that tags for part of speech.
- Tag your first book chapter for part of speech. 
- Use something like `head(...(book[1]))` to print out the first few examples. 

```{r}
##r chunk
create_tagger <- rdr_model(language = "English", annotation = "POS")
first_chap <- rdr_pos(create_tagger, x = sentence)
head(first_chap)
```

## spaCy

- Import spacy and the English language module.
- Tag the first chapter of your book using spacy, and print out the results. 
- Use the `pandas` option at the beginning of the lecture to print out only a few rows. 

```{python}
##python chunk
nlp = spacy.load('en_core_web_sm')
tagged_sentence = nlp(book_data)
py_pos_tagged = [(word.text, word.pos_, word.tag_) for word in tagged_sentence]
#py_pos_tagged
pd.DataFrame(py_pos_tagged).T
```

## Training your own tagger

- Create a Default tagger in Python using `nltk`. 
- The default option should be "NN" for nouns.
- You do not have to use the tagger yet, just create it for a combined tagger to use later. (Don't tag! Don't print it out!)

```{python}
##python chunk
default_tagger = nltk.DefaultTagger('NN')

#just randomly picking the words
#news	Chicago Tribune: Society Reportage
#reviews	Time Magazine: Reviews
#tokens = brown.words(categories =["news", "reviews"])
#tag those words!
#pd.DataFrame(default_tagger.tag(tokens)).head
#how good of the tagging
#brown_tagged_sents = brown.tagged_sents()
#default_tagger.evaluate(brown_tagged_sents)
#0.13130472824476916
```

## Unigram Tagger 

- Create a unigram tagger that is trained on the entire Brown corpus with tagged sentences. 
  - Import the Brown corpus.
  - Split the data into test and train. 
  - Train your unigram tagger on the training sentences.
  - Use the default tagger you created above as the backoff. 
  - Do not use the tagger here, just train it. 

```{python}
##python chunk
from nltk.corpus import brown

brown_tagged_sents = brown.tagged_sents()
#separate the data into train and test
size = int(len(brown_tagged_sents) * 0.7)
train_ = brown_tagged_sents[:size]
test_ = brown_tagged_sents[size:]

##create a function (training) on the first part
unigram_tagger = nltk.UnigramTagger(train_)

#combining taggers
#single words in context, go back to noun if necessary
t1 = nltk.UnigramTagger(train_, backoff=default_tagger)
##double words in context, back up to single words
t2 = nltk.BigramTagger(train_, backoff=t1)
```

## Evaluate

- Use the `.evaluate` function on your testing data to determine the accuracy of your tagger. 

```{python}
##python chunk
##test on the second part:
unigram_tagger.evaluate(test_)
#test on the first part:
t1.evaluate(test_)
#test on the combined 
t2.evaluate(test_)
```

## Apply to Harry Potter

- Use the tagger you created above to apply to the first chapter of your Harry Potter book.
- Hint: save your book as only the first chapter and then transfer to python to help make this shorter. 
- Second hint: be sure to tokenize the data first!
- Use something like `tagger.tag(book)[1:10]` to print out only the first ten tags. 

```{python}
##python chunk
tokens = nltk.word_tokenize(book_data)
print(unigram_tagger.tag(tokens)[1:10])
print(t1.tag(tokens)[1:10])
print(t2.tag(tokens)[1:10])
```

## Compare Results

- Examine the output from the different taggers we used to tag Harry Potter.\
**The R tagger package and the RDR POST Tagger has the same results. Spacy shows result. The self-created unigram tagger may be more efficient.**
- Are there any immediate differences you can notice when tagging?\
**There is not immediate differences from Unigram Tagger and RDR POS Tagger.RDR POS Tagger shows "SPACE" tagger but Unigram Tagger not.**
- Which tagger seems like the easiest to apply?\
**RDR POS Tagger seems much easier to apply, but Unigram Tagger could be more accurate if the data set is different.**
- Why might the Brown corpus not be very good at tagging Harry Potter books?\
**As known the Brown Corpus is an electronic collection of text samples of American English for 1960s, which make the results are slightly out of date. Also,Brown Corpus only sampled from 15 different text categories. Then, Harry Potter books are the modern books that contain magical contents that differ from standardized texts. **